{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# NLE Assignment: Sentiment Classification\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "outputs": [],
      "source": [
        "candidateno=123456 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk8JTP88A8vs",
        "outputId": "6a3b6eb4-f7b3-4536-e9b5-3b6d2c95b5a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "outputs": [],
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def get_train_test_data():\n",
        "    \n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "   \n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "   \n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJLegkdPFUJA",
        "outputId": "c8463f38-ae03-4554-eeae-a27cb9c0980e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['with', 'storytelling', 'this', 'compelling', ',', ...], 'pos')\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE3bKQbB50Rq"
      },
      "source": [
        "1)  \n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkT9CWv250Rq",
        "outputId": "65fdfb8d-04ad-4592-c910-9b9b21f8e4fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#essential imports and downloads\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "#constructing bag of words\n",
        "training_basic=[(FreqDist(wordlist),label) for (wordlist,label) in training_data]\n",
        "#training_basic[0]\n",
        "#for the testing\n",
        "testing_basic=[(FreqDist(wordlist),label) for (wordlist,label) in testing_data]\n",
        "\n",
        "#getting rid of stopwords and punctation, also lemmatizing\n",
        "stop = stopwords.words('english')\n",
        "lemm = WordNetLemmatizer()\n",
        "def normalise(wordlist):\n",
        "    token=[word for word in wordlist if word.isalpha() and word not in stop]\n",
        "    number_normalisation = [\"NUM\" if token.isdigit() else token for token in token]\n",
        "    filtered = [lemm.lemmatize(token) for token in number_normalisation]\n",
        "    return filtered\n",
        "##normalise(training_data[0][0])\n",
        "\n",
        "#creating an insatnce variable for easier retriaval of data for the future\n",
        "training_normalised=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in training_data]\n",
        "#for the testing\n",
        "testing_normalised=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in testing_data]\n",
        "##list(training_normalised[1])\n",
        "\n",
        "#checks the frequency of each word in our all training data, this is the part where it trains on the data\n",
        "pos_freq_dist=FreqDist()\n",
        "neg_freq_dist=FreqDist()\n",
        "for reviewDist,label in training_normalised:\n",
        "    if label=='pos':\n",
        "        pos_freq_dist+=reviewDist\n",
        "    else:\n",
        "        neg_freq_dist+=reviewDist\n",
        "        \n",
        "\n",
        "def most_frequent_words(posfrequency,negfrequency,topk):\n",
        "    diff=posfrequency-negfrequency\n",
        "    sorteddiff=diff.most_common()\n",
        "    most_common_words=[word for (word,freq) in sorteddiff[:topk]]\n",
        "    return most_common_words\n",
        "\n",
        "#creating an insatnce variable for top ten most frequent positive words in training documents\n",
        "top_pos=most_frequent_words(pos_freq_dist,neg_freq_dist,10)\n",
        "\n",
        "#creating an insatnce variable for top ten most frequent negative words in training documents\n",
        "top_neg=most_frequent_words(neg_freq_dist,pos_freq_dist,10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B8cgdi7t7MV",
        "outputId": "da6169ae-1a3d-4a74-a65b-ea505934dd56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['film', 'life', 'also', 'well', 'great', 'story', 'many', 'performance', 'love', 'best']\n"
          ]
        }
      ],
      "source": [
        "#a list of 10 content words which are representative of the positive reviews in the training data\n",
        "print(top_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIqSAumd50Rs",
        "outputId": "83ad88eb-4333-472e-b3cb-92d921324f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['movie', 'bad', 'plot', 'get', 'even', 'minute', 'script', 'worst', 'nothing', 'guy']\n"
          ]
        }
      ],
      "source": [
        "#a list of 10 content words which are representative of the negative reviews in the training data\n",
        "print(top_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zljze_ZJ50Rt"
      },
      "source": [
        "Firstly, what I have to do is to train on the data provided so I could extract the top 10 most used vocabulary in positive and negative documents.\n",
        "\n",
        "I have used freqdist to generate bag-of-words for each document and I made everything to be stored in a list, also I have kept the labels and made to be appeared at the end of list for the future. I ignore the ordering of the words in the documentation because I care which words are in the document not where in the sentence it is located. This was essential because we are looking for the vocabulary size.\n",
        "\n",
        "After that, I had to make a function called normalise that applies pre-processing to my worldlists since the most common words were punctuation, stopwords, and some words had unwanted affixes. Therefore, I decided to apply function normalise to the worldlist, it will return list of tokens that are purely of content words. I am doing this because tokens such as punctuation  and stopwords are difficult or impossible to categorise. Furthermore, I made sure that the tokens will be stemmed since we do not want to distinguish  lexical variation and its morphological variants. This was essential because we are looking for the vocabulary size.\n",
        "\n",
        "Later that, I recreated the bag-of-words representations and I made it to store the results in training_normalised. It makes use of normalise() function. I did this so I could get normalised tokens easily later on my code.\n",
        "\n",
        "Next, I needed to find the frequency of each words occurring in our positive and negative training data in total. Therefore, I have put code where it returns a total of the FreqDists for positive data and for negative data.\n",
        "\n",
        "Lastly, I have put a function most_frequent_words(), it takes two different total frequency distributions and a natural number, and then it returns the most freqent tokens/words in positive/negative class. Firstly, I get the difference between the two total frequency distributions.\n",
        "After that, I have used the most_common() method from the FreqDist class - this returns a list of words, frequency pairs ordered by frequency. In the end, it returned a list of 10 content words which are representative of the positive/negative reviews in the training data\n",
        "\n",
        "Finally, I have created variables for top ten most frequent words in positive/negative documents then I just printed them out separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2) \n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vk4EPLxZykuz",
        "outputId": "075108e4-720a-4fbe-d403-01f1c0176d9e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neg'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#essential imports\n",
        "from nltk.classify.api import ClassifierI\n",
        "\n",
        "#the class is a child of class called ClassifierI\n",
        "class  My_word_list_classifier(ClassifierI): \n",
        "    #asking for positive and negative vocabulary\n",
        "    def __init__(self, pos, neg): \n",
        "        self._pos = pos \n",
        "        self._neg = neg \n",
        "    \n",
        "    def classify(self, doc): \n",
        "        score = 0\n",
        "        for word,value in doc.items():\n",
        "            if word in self._pos:\n",
        "                score+=value\n",
        "            if word in self._neg:\n",
        "                score-=value\n",
        "        return \"neg\" if score < 0 else \"pos\" \n",
        "\n",
        "    def labels(self): \n",
        "        return (\"pos\", \"neg\")\n",
        "\n",
        "\n",
        "my_classifier = My_word_list_classifier(top_pos, top_neg)\n",
        "#Example usage\n",
        "my_classifier.classify(FreqDist(\"This movie was horrible\".split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xxvcyr50Rv"
      },
      "source": [
        "Firstly, I have used ClassifierI class as my parent class for my classifier. ClassifierI is an interface for labeling tokens with category labels. I have used ClassifierI because the interface should be used for \"single-category\n",
        "classification\" where the set of categories are known and the there is a finite number of categories. Also, each text/document belongs to exactly one\n",
        "category.\n",
        "\n",
        "After that, my constructor \"__init__\" will initialise positive and negative vocabulary which then will be used in the classify method.\n",
        "\n",
        "I decided to take the approach of scoring the documents, meaning that if a document's score were negative then it would mean that the document is in a negative category, and vice versa with positive. The classify method is defined so that each occurrence of a negative vocabulary decrements the score, and each occurrence of a positive vocabulary increments the score. \n",
        "\n",
        "There was no need to define the classify_many method as it is provided in ClassifierI.\n",
        "\n",
        "The labels method returns the list of category labels used by the classifier.\n",
        "\n",
        "Finally, I created an instance variable called my_classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL1iL9jg50Rv"
      },
      "source": [
        "3)\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq4Fmr8S50Rx"
      },
      "outputs": [],
      "source": [
        "class ConfusionMatrix:\n",
        "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
        "    \n",
        "        (self.c1,self.c2)=classes\n",
        "        self.predictions=predictions\n",
        "        self.TP=0\n",
        "        self.FP=0\n",
        "        self.FN=0\n",
        "        self.TN=0\n",
        "        for p,g in zip(predictions,goldstandard):\n",
        "            if g==self.c1:\n",
        "                if p==self.c1:\n",
        "                    self.TP+=1\n",
        "                else:\n",
        "                    self.FN+=1\n",
        "        \n",
        "            elif p==self.c1:\n",
        "                self.FP+=1\n",
        "            else:\n",
        "                self.TN+=1\n",
        "        \n",
        "    def accuracy(self):\n",
        "        a=0\n",
        "        a = (self.TP + self.TN)/(self.TP + self.TN + self.FP + self.FN)\n",
        "        return a\n",
        "\n",
        "    def precision(self):\n",
        "        p=0\n",
        "        p = self.TP / (self.TP + self.FP)\n",
        "        return p\n",
        "  \n",
        "    def recall(self):\n",
        "        r=0\n",
        "        r = self.TP / (self.TP + self.FN)\n",
        "        return r\n",
        "  \n",
        "    def f1(self):\n",
        "        f1=0\n",
        "        p=self.precision()\n",
        "        r=self.recall()\n",
        "        f1= 2*p*r/(p+r)\n",
        "        return f1 \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJhRGovu50Ry",
        "outputId": "2bf88f62-fd53-4487-a850-6ffdd1e4e345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of the classifier is 0.6216666666666667\n",
            "The precision of the classifier is 0.5905707196029777\n",
            "The recall of the classifier is 0.7933333333333333\n",
            "The F1 of the classifier is 0.6770981507823612\n"
          ]
        }
      ],
      "source": [
        "docs,labels=zip(*testing_normalised)\n",
        "senti_cm=ConfusionMatrix(my_classifier.classify_many(docs),labels)\n",
        "\n",
        "print(\"The accuracy of the classifier is {}\".format(senti_cm.accuracy()))\n",
        "print(\"The precision of the classifier is {}\".format(senti_cm.precision()))\n",
        "print(\"The recall of the classifier is {}\".format(senti_cm.recall()))\n",
        "print(\"The F1 of the classifier is {}\".format(senti_cm.f1()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gHYwj0i50Ry"
      },
      "source": [
        "It is a bad practice to evaluate/compare classifiers with accuracy, since it boils the performance of the model down to one number, and you are not seeing where classifiers getting things wrong, and where it's getting them right, and how it is achieving that. Particularly when there are imbalanced classes for example, 1% of documents are negative and other 99% are positive, then that would be quite misleading since a classifier that would label all the documents positive then its accuracy would have been 99% (which is wrong). Therefore, using other metrics for evaluation/comparison such as precision, recall and F1 score is safer and more useful.\n",
        "\n",
        "However, the time that accuracy would be useful is when the number of different labelled documents are perfectly balanced, for example, 50% positive and 50% negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "4) \n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xU2_jJCwC-u"
      },
      "outputs": [],
      "source": [
        "#essential imports\n",
        "from nltk.probability import DictionaryProbDist, ELEProbDist, FreqDist, sum_logs\n",
        "from nltk.classify.util import names_demo\n",
        "\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(training_normalised)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "optR0ZUJAMrs",
        "outputId": "6d6df395-e71e-44ff-cd9b-c46f1b622d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of Naive Bayes Classifier is 74.0000%\n",
            "The precision of Naive Bayes Classifier is 66.2896%\n",
            "The recall of Naive Bayes Classifier is 97.6667%\n",
            "The F1 of Naive Bayes Classifier is 78.9757%\n",
            "----------------------------------------------------\n",
            "The accuracy of my classifier is 62.1667%\n",
            "The precision of my classifier is 59.0571%\n",
            "The recall of my classifier is 79.3333%\n",
            "The F1 of my classifier is 67.7098%\n"
          ]
        }
      ],
      "source": [
        "senti_cm=ConfusionMatrix(my_classifier.classify_many(docs),labels)\n",
        "senti_cm_nbc=ConfusionMatrix(nb_classifier.classify_many(docs),labels)\n",
        "\n",
        "def percentage(number):\n",
        "  percentage_number = \"{:.4%}\".format(number)\n",
        "  return percentage_number\n",
        "\n",
        "print(\"The accuracy of Naive Bayes Classifier is {}\".format(percentage(senti_cm_nbc.accuracy())))\n",
        "print(\"The precision of Naive Bayes Classifier is {}\".format(percentage(senti_cm_nbc.precision())))\n",
        "print(\"The recall of Naive Bayes Classifier is {}\".format(percentage(senti_cm_nbc.recall())))\n",
        "print(\"The F1 of Naive Bayes Classifier is {}\".format(percentage(senti_cm_nbc.f1())))\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"The accuracy of my classifier is {}\".format(percentage(senti_cm.accuracy())))\n",
        "print(\"The precision of my classifier is {}\".format(percentage(senti_cm.precision())))\n",
        "print(\"The recall of my classifier is {}\".format(percentage(senti_cm.recall())))\n",
        "print(\"The F1 of my classifier is {}\".format(percentage(senti_cm.f1())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuYer9U50Rz"
      },
      "source": [
        "As we can see, overall, the Naïve Bayes Classifier beats in all of the metrics. Especially, in recall where the Naïve Bayes Classifier has got around 18.33% more than my classifier, this means that the Naïve Bayes is better at finding true positives, i.e., it is better at correctly predicting what category the documents actually belong to.\n",
        "\n",
        "When it comes to precision, again, the Naïve Bayes Classifier is around 7.23%‬ better than my classifier, that means that the Naïve Bayes Classifier produces less false positives than my classifier. \n",
        "\n",
        "Due to the fact the Naïve Bayes Classifier has better recall and precision, the F1 score of the Naïve Bayes Classifier will automatically be better than my classifier. Respectively, the Naïve Bayes Classifier has achieved around 11.26% more in F1 score than my classifier. This gives us overall measure to say that the Naïve Bayes Classifier model is performing better than the classifier that uses 10 most frequent words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "5) \n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PVBBPhh50R0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLQabgKFPvqN"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier_mf(My_word_list_classifier):\n",
        "    \n",
        "    def __init__(self,k):\n",
        "        self._k=k\n",
        "    \n",
        "    def train(self,training_data):\n",
        "        pos_freq_dist=FreqDist()\n",
        "        neg_freq_dist=FreqDist()\n",
        "\n",
        "        for reviewDist,label in training_data:\n",
        "            if label=='pos':\n",
        "                pos_freq_dist+=reviewDist\n",
        "            else:\n",
        "                neg_freq_dist+=reviewDist\n",
        "                \n",
        "        self._pos=most_frequent_words(pos_freq_dist,neg_freq_dist,self._k)\n",
        "        self._neg=most_frequent_words(neg_freq_dist,pos_freq_dist,self._k)\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "QBAY7kQr4964",
        "outputId": "5a7af8af-34d1-427c-a11a-8edf49885b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The F1 of 2WLS Word List Classifier classifier is 0.6463245492371705\n",
            "The F1 of 50WLS Word List Classifier classifier is 0.7130214917825537\n",
            "The F1 of 500WLS Word List Classifier classifier is 0.7309136420525658\n",
            "The F1 of 2000WLS Word List Classifier classifier is 0.7123947051744886\n",
            "The F1 of 2WLS Word List Classifier classifier is 0.6463245492371705\n",
            "The F1 of 50WLS Word List Classifier classifier is 0.7130214917825537\n",
            "The F1 of 500WLS Word List Classifier classifier is 0.7309136420525658\n",
            "The F1 of 2000WLS Word List Classifier classifier is 0.7123947051744886\n",
            "The F1 of 2WLS Word List Classifier classifier is 0.6463245492371705\n",
            "The F1 of 50WLS Word List Classifier classifier is 0.7130214917825537\n",
            "The F1 of 500WLS Word List Classifier classifier is 0.7309136420525658\n",
            "The F1 of 2000WLS Word List Classifier classifier is 0.7123947051744886\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02007f27-7aff-4113-9547-9585a6564aa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2WLS Word List Classifier</td>\n",
              "      <td>0.646325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50WLS Word List Classifier</td>\n",
              "      <td>0.713021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500WLS Word List Classifier</td>\n",
              "      <td>0.730914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000WLS Word List Classifier</td>\n",
              "      <td>0.712395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02007f27-7aff-4113-9547-9585a6564aa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02007f27-7aff-4113-9547-9585a6564aa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02007f27-7aff-4113-9547-9585a6564aa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              0         1\n",
              "0     2WLS Word List Classifier  0.646325\n",
              "1    50WLS Word List Classifier  0.713021\n",
              "2   500WLS Word List Classifier  0.730914\n",
              "3  2000WLS Word List Classifier  0.712395"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "distinct_hyperparameter_classifiers={\"2WLS Word List Classifier\":SimpleClassifier_mf(2),\n",
        "             \"50WLS Word List Classifier\":SimpleClassifier_mf(50),\n",
        "             \"500WLS Word List Classifier\":SimpleClassifier_mf(500),\n",
        "             \"2000WLS Word List Classifier\":SimpleClassifier_mf(2000)}\n",
        "\n",
        "number_of_runs=3\n",
        "results={}\n",
        "for key in distinct_hyperparameter_classifiers.keys():\n",
        "    results[key]=0\n",
        "\n",
        "for i in range(number_of_runs):\n",
        "    training,testing=get_train_test_data()\n",
        "    docs,labels=zip(*testing_normalised)\n",
        "    for name,classifier in distinct_hyperparameter_classifiers.items():\n",
        "        classifier.train(training_normalised)\n",
        "        cm=ConfusionMatrix(classifier.classify_many(docs),labels)   \n",
        "        print(\"The F1 of {} classifier is {}\".format(name,cm.f1()))\n",
        "        results[name]=results[name]+(cm.f1()/number_of_runs)\n",
        "\n",
        "df = pd.DataFrame(list(results.items()))\n",
        "display(df)\n",
        "ax = df.plot.bar(title=\"Experimental Results\",legend=False,x=0)\n",
        "ax.set_ylabel(\"Classifier F1-score\")\n",
        "ax.set_xlabel(\"Classifier\")\n",
        "ax.set_ylim(0,1.0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nYZVd15L50R2"
      },
      "source": [
        "# Design Decision\n",
        "I considered the following length of the wordlists: 2, 50, 500, and 2000.\n",
        "\n",
        "I have used F1 as the measurement since F1 score is the overall measure to say which model is performing best. I decided to run this experiment 3 times, meaning that the F1 results (on the graph) for each classifier is the average across three runs.\n",
        "\n",
        "After that, I plot the F1 results on the bar chart graph. I plot the F1 results on the y axis, and the classifiers on the x axis. \n",
        "\n",
        "# Conclusion\n",
        "We can see on the graph that classifier with 2 word length size has scored the worst overall. Whereas, classifier with 500 word length size has scored the best overall. However, this does not mean that the bigger the hyperparameter the better the classifier, this is visible when we look at 2000 word length size classifier, we can see that it has scored 0.018519 less than the 500 one. This can be attributed to the model becoming too complex with the increased word length size, which may be introducing unnecessary noise or variance into the model, causing the performance to drop.\n",
        "\n",
        "# Word List vs Naïve Bayes\n",
        "The Naïve Bayes Classifier is still a better classifier since its F1 score was 78.9757%; scored 0.058843 more‬ than the best word list classifier in the experiment. Therefore, I would recommend the Naïve Bayes Classifier for the future use. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34rdlS_iPov6",
        "outputId": "1ac9b874-5b1b-471b-d793-b47afc3570a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Submission length is 1044\n"
          ]
        }
      ],
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 437\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "filepath='/content/drive/My Drive/NLE Notebooks/NLassignment2022.ipynb'\n",
        "question_count=437\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
